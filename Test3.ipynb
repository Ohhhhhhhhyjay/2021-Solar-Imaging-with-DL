{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.1 64-bit"
  },
  "interpreter": {
   "hash": "f06167d67f7d333834d778cba2aba1bad99950d0b55c8f4f285a548d8beae30f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "import sunpy.map\r\n",
    "import os\r\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\r\n",
    "from tensorflow.keras.layers.experimental.preprocessing import CenterCrop\r\n",
    "\r\n",
    "import datetime\r\n",
    "import time\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import IPython.display as display\r\n",
    "\r\n",
    "import flares as fl\r\n",
    "import data_prep as prep"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  # 这一行注释掉就是使用gpu，不注释就是使用cpu"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The Layout of the program\r\n",
    "\r\n",
    "The basic layout of the program is as such:\r\n",
    "First getting a index dataset as a index of all fits data, since there is not enough memory to read all data at once. Then complile all the necessary functions and initialize the neural networks. Finally it reads data in batches and trains. So the main function is only at the beginning and the end of this notebook. Middle parts are all function definitions. This should make this program less messy than it seems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Training\r\n",
    "PATH = r'E:\\Program Files\\VSCode\\2021_ImagingWithDeepLearning\\my_test_data_7'\r\n",
    "# Validation\r\n",
    "# PATH = r'E:\\Program Files\\VSCode\\2021_ImagingWithDeepLearning\\my_val_data_2'\r\n",
    "\r\n",
    "INPUT_CHANNELS = 9\r\n",
    "OUTPUT_CHANNELS = 1\r\n",
    "INPUT_SHAPE = [512, 512, 9]\r\n",
    "OUTPUT_SHAPE = [512, 512, 1]\r\n",
    "Scaler_aia = Rescaling(scale=1.0 / 64000)\r\n",
    "Scaler_hmi = Rescaling(scale=1.0 / 76000)\r\n",
    "Cropper = CenterCrop(height=512, width=512)\r\n",
    "\r\n",
    "RAND_BUFFER_SIZE = 1000\r\n",
    "BATCH_SIZE = 1\r\n",
    "INDEX_BATCH_SIZE = 20 # As much as my memory can hold.\r\n",
    "\r\n",
    "LAMBDA = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Prep\r\n",
    "\r\n",
    "Load data from fits files, apply normalization to 0~1 and random jittering."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Define Random Jitter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def resize(input_image, real_image, height, width):\r\n",
    "  input_image = tf.image.resize(input_image, [height, width],\r\n",
    "                                method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n",
    "  real_image = tf.image.resize(real_image, [height, width],\r\n",
    "                               method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\r\n",
    "\r\n",
    "  return input_image, real_image\r\n",
    "  \r\n",
    "def random_crop(input_image, real_image):\r\n",
    "  stacked_image = tf.stack([input_image, real_image], axis=0)\r\n",
    "  cropped_image = tf.image.random_crop(\r\n",
    "      stacked_image, size=[2, 512, 512, 9])\r\n",
    "\r\n",
    "  return cropped_image[0], cropped_image[1]\r\n",
    "  \r\n",
    "@tf.function()\r\n",
    "def random_jitter(input_image, real_image):\r\n",
    "  # Resizing\r\n",
    "  input_image, real_image = resize(input_image, real_image, 600, 600)\r\n",
    "\r\n",
    "  # Random cropping back\r\n",
    "  input_image, real_image = random_crop(input_image, real_image)\r\n",
    "\r\n",
    "  if tf.random.uniform(()) > 0.5:\r\n",
    "    # Random mirroring\r\n",
    "    input_image = tf.image.flip_left_right(input_image)\r\n",
    "    real_image = tf.image.flip_left_right(real_image)\r\n",
    "\r\n",
    "  return input_image, real_image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Data!!!\r\n",
    "\r\n",
    "Let's dance."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Make a multi-channels dataset\r\n",
    "dataset_fits_list = []\r\n",
    "for i in range(INPUT_CHANNELS + 1): # Walk all directories\r\n",
    "    path = os.path.join(PATH, str(i))\r\n",
    "    fits_list = fl.get_fits_list(path)\r\n",
    "    dataset_fits_list.append(fits_list)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dataset_fits_list = np.array(dataset_fits_list)\r\n",
    "dataset_fits_list = np.array(list(zip(*dataset_fits_list))) # 将其横向组合"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "index_dataset = tf.data.Dataset.from_tensor_slices(dataset_fits_list)\r\n",
    "\r\n",
    "index_train_dataset = index_dataset.take(160)\r\n",
    "index_test_dataset = index_dataset.skip(160)\r\n",
    "\r\n",
    "index_train_dataset = index_train_dataset.shuffle(RAND_BUFFER_SIZE)\r\n",
    "index_train_dataset = index_train_dataset.batch(INDEX_BATCH_SIZE)\r\n",
    "\r\n",
    "index_test_dataset = index_test_dataset.batch(100) # Just to have access with 'for'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_dataset(dataset_fits_list): # new\r\n",
    "    \"\"\"Generate dataset from a fits list. The list is like:\r\n",
    "    [\r\n",
    "    [output_dir//0//xxxx.fits, output_dir//1//xxxx.fit, ...]\r\n",
    "    [output_dir//0//xxxx.fits, output_dir//1//xxxx.fit, ...]\r\n",
    "    [output_dir//0//xxxx.fits, output_dir//1//xxxx.fit, ...]\r\n",
    "    ...\r\n",
    "    [output_dir//0//xxxx.fits, output_dir//1//xxxx.fit, ...]\r\n",
    "    ]\r\n",
    "    \"\"\"\r\n",
    "    examples = []\r\n",
    "    labels = []\r\n",
    "    for set in dataset_fits_list:\r\n",
    "        all_channels = []\r\n",
    "        for fits in set:\r\n",
    "            fits = fits.numpy().decode() # fits \r\n",
    "            telescope = prep.TelescopeFits(fits)\r\n",
    "            if 'AIA' in telescope:\r\n",
    "                data = prep.AIAPrep(fits, Scaler_aia, Cropper)\r\n",
    "            if 'HMI' in telescope:\r\n",
    "                data = prep.HMIPrep(fits, Scaler_aia, Cropper)    \r\n",
    "            all_channels.append(data)\r\n",
    "\r\n",
    "        input_channel = tf.concat(all_channels[:-1], axis=2)\r\n",
    "        examples.append(input_channel)\r\n",
    "\r\n",
    "        zeros = tf.zeros([512, 512, 8])\r\n",
    "        output_channel = tf.concat([all_channels[-1], zeros], axis=2)\r\n",
    "        labels.append(output_channel)\r\n",
    "    \r\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((examples, labels))\r\n",
    "\r\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare train and test dataset!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def extract_dim(input_image, real_image):\r\n",
    "    unstacked = tf.unstack(real_image, axis=2)\r\n",
    "    real_image = unstacked[0]\r\n",
    "    real_image = tf.expand_dims(real_image, 2)\r\n",
    "    return input_image, real_image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def prep_train_dataset(dataset):\r\n",
    "    # Repeat and apply random jitter to make more use of limited data.\r\n",
    "    train_dataset = dataset.repeat(2)\r\n",
    "    train_dataset = train_dataset.map(random_jitter)\r\n",
    "\r\n",
    "    # Eliminate redundant channels in output images\r\n",
    "    train_dataset = train_dataset.map(extract_dim)\r\n",
    "\r\n",
    "    # Separate into batches\r\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE)\r\n",
    "\r\n",
    "    return train_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construct(Define) the Generator, Discriminator, Loss Function, Fit Function and Checkpoint"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def downsample(filters, size, apply_batchnorm=True):\r\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\r\n",
    "\r\n",
    "  result = tf.keras.Sequential()\r\n",
    "  result.add(\r\n",
    "      tf.keras.layers.Conv2D(filters, size, strides=2, padding='same',\r\n",
    "                             kernel_initializer=initializer, use_bias=False))\r\n",
    "\r\n",
    "  if apply_batchnorm:\r\n",
    "    result.add(tf.keras.layers.BatchNormalization())\r\n",
    "\r\n",
    "  result.add(tf.keras.layers.LeakyReLU())\r\n",
    "\r\n",
    "  return result\r\n",
    "\r\n",
    "def upsample(filters, size, apply_dropout=False):\r\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\r\n",
    "\r\n",
    "  result = tf.keras.Sequential()\r\n",
    "  result.add(\r\n",
    "    tf.keras.layers.Conv2DTranspose(filters, size, strides=2,\r\n",
    "                                    padding='same',\r\n",
    "                                    kernel_initializer=initializer,\r\n",
    "                                    use_bias=False))\r\n",
    "\r\n",
    "  result.add(tf.keras.layers.BatchNormalization())\r\n",
    "\r\n",
    "  if apply_dropout:\r\n",
    "      result.add(tf.keras.layers.Dropout(0.5))\r\n",
    "\r\n",
    "  result.add(tf.keras.layers.ReLU())\r\n",
    "\r\n",
    "  return result\r\n",
    "  \r\n",
    "def Generator():\r\n",
    "  inputs = tf.keras.layers.Input(shape=INPUT_SHAPE)\r\n",
    "\r\n",
    "  down_stack = [\r\n",
    "    downsample(64, 4, apply_batchnorm=False),  # 64 convolution kernels with size 4*4\r\n",
    "    downsample(128, 4),  # 128 convolution kernels with size 4*4\r\n",
    "    downsample(256, 4),  # (batch_size, 32, 32, 256)\r\n",
    "    downsample(512, 4),  # (batch_size, 16, 16, 512)\r\n",
    "    downsample(512, 4),  # (batch_size, 8, 8, 512)\r\n",
    "    downsample(512, 4),  # (batch_size, 4, 4, 512)\r\n",
    "    downsample(512, 4),  # (batch_size, 2, 2, 512)\r\n",
    "    downsample(512, 4),  # (batch_size, 1, 1, 512)\r\n",
    "  ]\r\n",
    "\r\n",
    "  up_stack = [\r\n",
    "    upsample(512, 4, apply_dropout=True),  # (batch_size, 2, 2, 1024)\r\n",
    "    upsample(512, 4, apply_dropout=True),  # (batch_size, 4, 4, 1024)\r\n",
    "    upsample(512, 4, apply_dropout=True),  # (batch_size, 8, 8, 1024)\r\n",
    "    upsample(512, 4),  # (batch_size, 16, 16, 1024)\r\n",
    "    upsample(256, 4),  # (batch_size, 32, 32, 512)\r\n",
    "    upsample(128, 4),  # (batch_size, 64, 64, 256)\r\n",
    "    upsample(64, 4),  # (batch_size, 128, 128, 128)\r\n",
    "  ]\r\n",
    "\r\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\r\n",
    "  last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,\r\n",
    "                                         strides=2,\r\n",
    "                                         padding='same',\r\n",
    "                                         kernel_initializer=initializer,\r\n",
    "                                         activation='tanh')  # (batch_size, 256, 256, 3)\r\n",
    "\r\n",
    "  x = inputs\r\n",
    "\r\n",
    "  # Downsampling through the model\r\n",
    "  skips = []\r\n",
    "  for down in down_stack:\r\n",
    "    x = down(x)\r\n",
    "    skips.append(x)\r\n",
    "\r\n",
    "  skips = reversed(skips[:-1])\r\n",
    "\r\n",
    "  # Upsampling and establishing the skip connections\r\n",
    "  for up, skip in zip(up_stack, skips):\r\n",
    "    x = up(x)\r\n",
    "    x = tf.keras.layers.Concatenate()([x, skip])\r\n",
    "\r\n",
    "  x = last(x)\r\n",
    "\r\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generator = Generator()\r\n",
    "loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generator_loss(disc_generated_output, gen_output, target):\r\n",
    "  gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)\r\n",
    "\r\n",
    "  # Mean absolute error\r\n",
    "  l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\r\n",
    "\r\n",
    "  # Max absolute error -maybe suitable for bright region\r\n",
    "  linf_loss = tf.abs(tf.reduce_max(target) - tf.reduce_max(gen_output))\r\n",
    "\r\n",
    "  total_gen_loss = gan_loss + (LAMBDA * l1_loss)\r\n",
    "\r\n",
    "  return total_gen_loss, gan_loss, l1_loss\r\n",
    "  \r\n",
    "def Discriminator():\r\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\r\n",
    "\r\n",
    "  inp = tf.keras.layers.Input(shape=INPUT_SHAPE, name='input_image')\r\n",
    "  tar = tf.keras.layers.Input(shape=OUTPUT_SHAPE, name='target_image')\r\n",
    "\r\n",
    "  x = tf.keras.layers.concatenate([inp, tar])  # (batch_size, 256, 256, channels*2)\r\n",
    "\r\n",
    "  down1 = downsample(64, 4, False)(x)  # (batch_size, 128, 128, 64)\r\n",
    "  down2 = downsample(128, 4)(down1)  # (batch_size, 64, 64, 128)\r\n",
    "  down3 = downsample(256, 4)(down2)  # (batch_size, 32, 32, 256)\r\n",
    "\r\n",
    "  zero_pad1 = tf.keras.layers.ZeroPadding2D()(down3)  # (batch_size, 34, 34, 256)\r\n",
    "  conv = tf.keras.layers.Conv2D(512, 4, strides=1,\r\n",
    "                                kernel_initializer=initializer,\r\n",
    "                                use_bias=False)(zero_pad1)  # (batch_size, 31, 31, 512)\r\n",
    "\r\n",
    "  batchnorm1 = tf.keras.layers.BatchNormalization()(conv)\r\n",
    "\r\n",
    "  leaky_relu = tf.keras.layers.LeakyReLU()(batchnorm1)\r\n",
    "\r\n",
    "  zero_pad2 = tf.keras.layers.ZeroPadding2D()(leaky_relu)  # (batch_size, 33, 33, 512)\r\n",
    "\r\n",
    "  last = tf.keras.layers.Conv2D(1, 4, strides=1,\r\n",
    "                                kernel_initializer=initializer)(zero_pad2)  # (batch_size, 30, 30, 1)\r\n",
    "\r\n",
    "  return tf.keras.Model(inputs=[inp, tar], outputs=last)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "discriminator = Discriminator()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def discriminator_loss(disc_real_output, disc_generated_output):\r\n",
    "  real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)\r\n",
    "\r\n",
    "  generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)\r\n",
    "\r\n",
    "  total_disc_loss = real_loss + generated_loss\r\n",
    "\r\n",
    "  return total_disc_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\r\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "checkpoint_dir = './training_checkpoints'\r\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\r\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\r\n",
    "                                 generator=generator,\r\n",
    "                                 discriminator=discriminator)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def generate_images(model, test_input, tar):\r\n",
    "  prediction = model(test_input, training=True)\r\n",
    "  plt.figure(figsize=(15, 12))\r\n",
    "\r\n",
    "  input_images = tf.unstack(test_input[0], axis=2)\r\n",
    "  input_images.append(tar[0])\r\n",
    "  input_images.append(prediction[0])\r\n",
    "  display_list = input_images # unstack input. Not sure if this could work.\r\n",
    "  title = ['Input Image(s)', 'Ground Truth', 'Predicted Image']\r\n",
    "\r\n",
    "  for i in range(INPUT_CHANNELS + 2):\r\n",
    "    plt.subplot(3, 4, i+1)# 3*4, 11 images in total\r\n",
    "    if i < INPUT_CHANNELS:\r\n",
    "      plt.title(title[0])\r\n",
    "    else:\r\n",
    "      plt.title(title[i - INPUT_CHANNELS + 1])\r\n",
    "    # Getting the pixel values in the [0, 1] range to plot.\r\n",
    "    plt.imshow(display_list[i] * 0.5 + 0.5)\r\n",
    "    plt.axis('off')\r\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "log_dir=\"logs/\"\r\n",
    "\r\n",
    "summary_writer = tf.summary.create_file_writer(\r\n",
    "  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@tf.function\r\n",
    "def train_step(input_image, target, step):\r\n",
    "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\r\n",
    "    gen_output = generator(input_image, training=True)\r\n",
    "\r\n",
    "    disc_real_output = discriminator([input_image, target], training=True)\r\n",
    "    disc_generated_output = discriminator([input_image, gen_output], training=True)\r\n",
    "\r\n",
    "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\r\n",
    "    disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\r\n",
    "\r\n",
    "  generator_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\r\n",
    "  discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\r\n",
    "\r\n",
    "  generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\r\n",
    "  discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\r\n",
    "\r\n",
    "  with summary_writer.as_default():\r\n",
    "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=step)\r\n",
    "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step)\r\n",
    "    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step)\r\n",
    "    tf.summary.scalar('disc_loss', disc_loss, step=step) # 原step//1000\r\n",
    "    \r\n",
    "def fit(train_ds, test_ds, steps):\r\n",
    "  example_input, example_target = next(iter(test_ds.take(1)))\r\n",
    "\r\n",
    "  for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():\r\n",
    "    if (step) % 1000 == 0:\r\n",
    "      start = time.time()\r\n",
    "      display.clear_output(wait=True)\r\n",
    "\r\n",
    "      if step != 0:\r\n",
    "        print(f'Time taken for 1000 steps: {time.time()-start} sec\\n')\r\n",
    "\r\n",
    "      generate_images(generator, example_input, example_target)\r\n",
    "      print(f\"Step: {step//1000}k\")\r\n",
    "\r\n",
    "    train_step(input_image, target, step)\r\n",
    "\r\n",
    "    # Training step\r\n",
    "    if (step+1) % 10 == 0:\r\n",
    "      print('.', end='', flush=True)\r\n",
    "\r\n",
    "    # Save (checkpoint) the model every 5k steps\r\n",
    "    if (step + 1) % 5000 == 0:\r\n",
    "      checkpoint.save(file_prefix=checkpoint_prefix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Construction Visualization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our Generator is constructed in a U shaped manner, with 14 + 7 layers. 14 convolution layes, 7 concatenate layers. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.keras.utils.plot_model(generator, show_shapes=True, dpi=64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.keras.utils.plot_model(discriminator, show_shapes=True, dpi=64)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load TensorBoard and Start Training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext tensorboard"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get test dataset\r\n",
    "for batch_fits_list in index_test_dataset:\r\n",
    "    test_dataset = get_dataset(batch_fits_list)\r\n",
    "    test_dataset = test_dataset.map(extract_dim)\r\n",
    "    test_dataset = test_dataset.batch(BATCH_SIZE)\r\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get train dataset and train\r\n",
    "for batch_fits_list in index_train_dataset:\r\n",
    "    train_dataset = get_dataset(batch_fits_list)\r\n",
    "    train_dataset = prep_train_dataset(train_dataset)\r\n",
    "    fit(train_dataset, test_dataset, steps=5000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save\r\n",
    "checkpoint.save(file_prefix=checkpoint_prefix)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Recap and Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the trained model on a few examples from the train set\r\n",
    "for inp, tar in train_dataset.take(10):\r\n",
    "    generate_images(generator, inp, tar)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the trained model on a few examples from the test set\r\n",
    "for inp, tar in test_dataset.take(10):\r\n",
    "    generate_images(generator, inp, tar)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Run the trained model on a few examples from the validation set\r\n",
    "for inp, tar in val_dataset.take(10):\r\n",
    "    generate_images(generator, inp, tar)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}